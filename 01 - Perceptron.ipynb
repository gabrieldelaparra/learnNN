{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "[Source](https://blog.dbrgn.ch/2013/3/26/perceptrons-in-python/)\n",
    "\n",
    "[Source2](https://brilliant.org/wiki/perceptron/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "\n",
    "Idea general del perceptrón:\n",
    "* Es un algoritmo de aprendizaje supervisado para clasificación.\n",
    "* Es la suma de las entradas x<sub>i</sub> ponderadas por pesos w<sub>i</sub>.\n",
    "* Se ocupa una función de activación a la salida de la neurona, en este caso el escalón.\n",
    "\n",
    "El entrenamiento consiste en:\n",
    "* A partir de los datos de entrada, el objetivo es calcular los pesos.\n",
    "\n",
    "Una vez entrenado:\n",
    "* Clasifica datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a necesitar:\n",
    "- Función que deseamos entrenar\n",
    "- Valores de entrenamiento\n",
    "- Pesos al azar\n",
    "- Función de activación\n",
    "- Hyper Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función a entrenar: OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| A | B | A or B |\n",
    "|---|---|--------|\n",
    "| 0 | 0 | 0      |\n",
    "| 0 | 1 | 1      |\n",
    "| 1 | 0 | 1      |\n",
    "| 1 | 1 | 1      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = [\n",
    "    #([valores de entrada], salida esperada)\n",
    "    ([0,0],0),\n",
    "    ([0,1],1),\n",
    "    ([1,0],1),\n",
    "    ([1,1],1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 1], [1, 0], [1, 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZNwlqUDGXZIKZNwlqUDGXZIK9P8lpwfTNtQAswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f6c1d1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = [i[0] for i in trainingData]\n",
    "colors = [i[1] for i in trainingData]\n",
    "print(inputs)\n",
    "x = [i[0] for i in inputs]\n",
    "y = [i[1] for i in inputs]\n",
    "plt.scatter(x, y, c=colors, cmap=\"bwr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesos iniciales\n",
    "Un aspecto de considerar de nuestro problema es que tendremos 3 pesos:\n",
    "* 2 entradas: $w_1$ de $A$ y $w_2$ de $B$ (`A` y `B` en la tabla) \n",
    "* 1 de bías: $w_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.12113703  0.64428499]\n",
      "Bias: 0.5225082353420727\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.rand(2)\n",
    "bias = random.random()\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(step(-1))\n",
    "print(step(-0.1))\n",
    "print(step(0))\n",
    "print(step(0.1))\n",
    "print(step(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "El entrenamiento está dado en 4 pasos:\n",
    "1. Empezar con valores al azar a los pesos $w(0)$ ($w_1$, $w_2$) y al bias $w_0$.\n",
    "2. Para cada entrada $x_i$, encontrar un arreglo de pesos $w$, tal que $w(t) \\cdot x_i + w_0 > 0$. Con $y_i$ la salida para la entrada $x_i$.\n",
    "3. Actualizar los pesos para la siguiente iteración:\n",
    "    - $w(t+1) = w(t) + \\alpha(d_i - y_i)x_i$\n",
    "    - $w_0(t+1) = w_0(t) + \\alpha(d_i - y_i)$\n",
    "4. Si el entrenamiento es offline (se entrenan con las mismas entradas), se repiten los pasos 2 y 3 hasta que se reduce el error lo suficiente.\n",
    "\n",
    "Desde los datos de entrenamiento tenemos:\n",
    "* $x_i$\n",
    "* $d_i$\n",
    "\n",
    "Para cada input, debemos calcular: \n",
    "* $y_i$\n",
    "\n",
    "Con los $y_i$, calculamos los nuevos pesos $w_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = [\n",
    "    #([valores de entrada], salida esperada)\n",
    "    ([0,0],0),\n",
    "    ([0,1],0),\n",
    "    ([1,0],0),\n",
    "    ([1,1],1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi: [0, 0]\n",
      "w0: 0\n"
     ]
    }
   ],
   "source": [
    "wi = [0, 0]\n",
    "w0 = 0\n",
    "print(\"wi:\", wi)\n",
    "print(\"w0:\", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 1; Iteración 1\n",
    "Valor entrenamiento $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [0, 0] di 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "xi, di = trainingData[i]\n",
    "print(\"xi:\", xi, \"di\", di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yi: 0\n"
     ]
    }
   ],
   "source": [
    "yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "print(\"yi:\", yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "di-yi: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"di-yi:\", di - yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new weigth: [ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "print(\"new weigth:\", wi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "w0 = w0 + learningRate*(di-yi)\n",
    "print(\"new bias:\", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 1; Iteración 2\n",
    "Valor entrenamiento $x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [0, 1] di 0\n",
      "yi: 0.0\n",
      "di-yi: 0.0\n",
      "new weigth: [ 0.  0.]\n",
      "new bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "xi, di = trainingData[i]\n",
    "print(\"xi:\", xi, \"di\", di)\n",
    "yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "print(\"yi:\", yi)\n",
    "print(\"di-yi:\", di - yi)\n",
    "wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "print(\"new weigth:\", wi)\n",
    "w0 = w0 + learningRate*(di-yi)\n",
    "print(\"new bias:\", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 1; Iteración 3\n",
    "Valor entrenamiento $x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1, 0] di 0\n",
      "yi: 0.0\n",
      "di-yi: 0.0\n",
      "new weigth: [ 0.  0.]\n",
      "new bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "xi, di = trainingData[i]\n",
    "print(\"xi:\", xi, \"di\", di)\n",
    "yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "print(\"yi:\", yi)\n",
    "print(\"di-yi:\", di - yi)\n",
    "wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "print(\"new weigth:\", wi)\n",
    "w0 = w0 + learningRate*(di-yi)\n",
    "print(\"new bias:\", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 1; Iteración 4\n",
    "Valor entrenamiento $x_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1, 1] di 1\n",
      "yi: 0.0\n",
      "di-yi: 1.0\n",
      "new weigth: [ 0.5  0.5]\n",
      "new bias: 0.5\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "xi, di = trainingData[i]\n",
    "print(\"xi:\", xi, \"di\", di)\n",
    "yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "print(\"yi:\", yi)\n",
    "print(\"di-yi:\", di - yi)\n",
    "wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "print(\"new weigth:\", wi)\n",
    "w0 = w0 + learningRate*(di-yi)\n",
    "print(\"new bias:\", w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 2;\n",
    "Todos los valores de entrenamiento de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [0, 0] di 0\n",
      "yi: 0.5\n",
      "di-yi: -0.5\n",
      "new weigth: [ 0.5  0.5]\n",
      "new bias: 0.25\n",
      "\n",
      "xi: [0, 1] di 0\n",
      "yi: 0.75\n",
      "di-yi: -0.75\n",
      "new weigth: [ 0.5    0.125]\n",
      "new bias: -0.125\n",
      "\n",
      "xi: [1, 0] di 0\n",
      "yi: 0.375\n",
      "di-yi: -0.375\n",
      "new weigth: [ 0.3125  0.125 ]\n",
      "new bias: -0.3125\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.125\n",
      "di-yi: 0.875\n",
      "new weigth: [ 0.75    0.5625]\n",
      "new bias: 0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trainingData)):\n",
    "    xi, di = trainingData[i]\n",
    "    yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "    wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "    w0 = w0 + learningRate*(di-yi)\n",
    "\n",
    "    print(\"xi:\", xi, \"di\", di)\n",
    "    print(\"yi:\", yi)\n",
    "    print(\"di-yi:\", di - yi)\n",
    "    print(\"new weigth:\", wi)\n",
    "    print(\"new bias:\", w0)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 3;\n",
    "Todos los valores de entrenamiento de nuevo. Esta vez, con print solo por la Epoch completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1, 1] di 1\n",
      "yi: 0.25\n",
      "di-yi: 0.75\n",
      "new weigth: [ 0.875  0.625]\n",
      "new bias: -0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trainingData)):\n",
    "    xi, di = trainingData[i]\n",
    "    yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "    wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "    w0 = w0 + learningRate*(di-yi)\n",
    "\n",
    "print(\"xi:\", xi, \"di\", di)\n",
    "print(\"yi:\", yi)\n",
    "print(\"di-yi:\", di - yi)\n",
    "print(\"new weigth:\", wi)\n",
    "print(\"new bias:\", w0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuando detenerse?\n",
    "Después de varias iteraciones, los pesos convergen a un valor del cual después no se modifican. En este caso, iteraremos hasta llegar a un delta (0.01) entre estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1, 1] di 1\n",
      "yi: 0.34375\n",
      "di-yi: 0.65625\n",
      "new weigth: [ 0.9375    0.671875]\n",
      "new bias: -0.28125\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.40625\n",
      "di-yi: 0.59375\n",
      "new weigth: [ 0.96875   0.703125]\n",
      "new bias: -0.375\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.4453125\n",
      "di-yi: 0.5546875\n",
      "new weigth: [ 0.984375    0.72265625]\n",
      "new bias: -0.4296875\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.46875\n",
      "di-yi: 0.53125\n",
      "new weigth: [ 0.9921875  0.734375 ]\n",
      "new bias: -0.4609375\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.482421875\n",
      "di-yi: 0.517578125\n",
      "new weigth: [ 0.99609375  0.74121094]\n",
      "new bias: -0.478515625\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.490234375\n",
      "di-yi: 0.509765625\n",
      "new weigth: [ 0.99804688  0.74511719]\n",
      "new bias: -0.48828125\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.49462890625\n",
      "di-yi: 0.50537109375\n",
      "new weigth: [ 0.99902344  0.74731445]\n",
      "new bias: -0.49365234375\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.4970703125\n",
      "di-yi: 0.5029296875\n",
      "new weigth: [ 0.99951172  0.74853516]\n",
      "new bias: -0.49658203125\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.498413085938\n",
      "di-yi: 0.501586914062\n",
      "new weigth: [ 0.99975586  0.74920654]\n",
      "new bias: -0.498168945312\n",
      "\n",
      "xi: [1, 1] di 1\n",
      "yi: 0.499145507812\n",
      "di-yi: 0.500854492188\n",
      "new weigth: [ 0.99987793  0.74957275]\n",
      "new bias: -0.4990234375\n",
      "\n",
      "Sucess\n"
     ]
    }
   ],
   "source": [
    "delta = 0.001\n",
    "while True:\n",
    "    old_wi = wi\n",
    "    old_w0 = w0\n",
    "    \n",
    "    for i in range(len(trainingData)):\n",
    "        xi, di = trainingData[i]\n",
    "        yi = xi[0]*wi[0] + xi[1]*wi[1] + w0\n",
    "        wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "        w0 = w0 + learningRate*(di-yi)\n",
    "\n",
    "    print(\"xi:\", xi, \"di\", di)\n",
    "    print(\"yi:\", yi)\n",
    "    print(\"di-yi:\", di - yi)\n",
    "    print(\"new weigth:\", wi)\n",
    "    print(\"new bias:\", w0)\n",
    "    print()\n",
    "    \n",
    "    if( (abs(old_wi - wi)  < delta).all() and abs(old_w0 - w0) < delta ):\n",
    "        print(\"Sucess\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecciones\n",
    "Algunos puntos importantes que revisamos durante este proceso:\n",
    "* Los pesos en este caso partieron en cero. Esto implica que siempre que se entrene este sistema con los mismos valores de entrada, se llegará al mismo resultado. Esto puede ser negativo en algunos casos y se recomienda iniciar los pesos con valores random:\n",
    "    - `wi = random.rand(2)`\n",
    "    - `w0 = random.random()`.\n",
    "* Para los 3 primeros valores de entrada, en la primera iteración, no se avanzó en nada. Esto puede pasar, sobre todo con miles de valores de entrada. Para generalizar más la solución, se recomienda tomar al azar los valores desde el set de entrada en cada iteración:\n",
    "    - `xi, di = random.choice(trainingData)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = [\n",
    "    ([0,0],0),\n",
    "    ([0,1],1),\n",
    "    ([1,0],1),\n",
    "    ([1,1],1),\n",
    "]\n",
    "learningRate = 0.2\n",
    "wi = np.random.rand(2)\n",
    "w0 = random.random()\n",
    "delta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xi: [1, 1] ; di: 1\n",
      "yi: 1.37424576277\n",
      "di-yi: -0.374245762765\n",
      "new weigth: [ 0.38099382  0.53330555]\n",
      "new bias: 0.23539893698\n",
      "\n",
      "xi: [1, 1] ; di: 1\n",
      "yi: 1.36397342666\n",
      "di-yi: -0.363973426656\n",
      "new weigth: [ 0.38320153  0.51618592]\n",
      "new bias: 0.246201918726\n",
      "\n",
      "xi: [1, 1] ; di: 1\n",
      "yi: 1.35607657485\n",
      "di-yi: -0.356076574854\n",
      "new weigth: [ 0.3844795   0.50234112]\n",
      "new bias: 0.255610013978\n",
      "\n",
      "xi: [1, 1] ; di: 1\n",
      "yi: 1.34953630207\n",
      "di-yi: -0.34953630207\n",
      "new weigth: [ 0.3850519   0.49106803]\n",
      "new bias: 0.26369458823\n",
      "\n",
      "xi: [1, 1] ; di: 1\n",
      "yi: 1.3440249898\n",
      "di-yi: -0.344024989799\n",
      "new weigth: [ 0.38512634  0.48185829]\n",
      "new bias: 0.270625365933\n",
      "\n",
      "Sucess\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    old_wi = wi\n",
    "    old_w0 = w0\n",
    "    \n",
    "    for i in range(len(trainingData)):\n",
    "        xi, di = trainingData[i]\n",
    "        yi = xi[0] * wi[0] + xi[1] * wi[1] + w0\n",
    "        wi = wi + learningRate*(di-yi)*np.array(xi)\n",
    "        w0 = w0 + learningRate*(di-yi)\n",
    "\n",
    "    print(\"xi:\", xi, \"; di:\", di)\n",
    "    print(\"yi:\", yi)\n",
    "    print(\"di-yi:\", di - yi)\n",
    "    print(\"new weigth:\", wi)\n",
    "    print(\"new bias:\", w0)\n",
    "    print()\n",
    "    \n",
    "    if( (abs(old_wi - wi)  < delta).all() and abs(old_w0 - w0) < delta ):\n",
    "        print(\"Sucess\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
