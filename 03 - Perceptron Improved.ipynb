{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our last notebook, we covered the basics about a perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  [0, 0] \tweights:\t [ 0.87258713  0.00123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [0, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t 0.4642126292852864\n",
      "inputs:  [1, 0] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t 0.4642126292852864\n",
      "inputs:  [1, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t 0.4642126292852864\n",
      "inputs:  [0, 0] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [0, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [1, 0] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [1, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [0, 0] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [0, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [1, 0] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "inputs:  [1, 1] \tweights:\t [ 0.87258713  0.50123648] \tbias:\t -0.03578737071471361\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "def step(x):\n",
    "    if x<0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "trainingData = [\n",
    "    #([input values], expected classes)\n",
    "    ([0,0],0),\n",
    "    ([0,1],1),\n",
    "    ([1,0],1),\n",
    "    ([1,1],1),\n",
    "]\n",
    "\n",
    "learningRate = 0.5\n",
    "\n",
    "w = np.random.rand(2)\n",
    "b = random.random()\n",
    "\n",
    "while True:\n",
    "    old_w = w\n",
    "    old_b = b\n",
    "    \n",
    "    for i in range(len(trainingData)):\n",
    "        x, di = trainingData[i]\n",
    "        yi = x[0] * w[0] + x[1] * w[1] + b\n",
    "        error = di - step(yi)\n",
    "        w = w + learningRate * error * np.array(x)\n",
    "        b = b + learningRate * error\n",
    "\n",
    "        print(\"inputs: \", x, \"\\tweights:\\t\", w, \"\\tbias:\\t\", b)\n",
    "    \n",
    "    if((old_w == w).all() and old_b == b):\n",
    "        print(\"Success!\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerceptron():\n",
    "    # Puntos:\n",
    "    inputs = [i[0] for i in trainingData]\n",
    "    colors = [i[1] for i in trainingData]\n",
    "    x = [i[0] for i in inputs]\n",
    "    y = [i[1] for i in inputs]\n",
    "    minX, maxX = np.array(x).min() - .1, np.array(x).max() + .1\n",
    "    minY, maxY = np.array(y).min() - .1, np.array(y).max() + .1\n",
    "\n",
    "    plt.ylim(minY, maxY)\n",
    "    plt.xlim(minX, maxX)\n",
    "    plt.scatter(x, y, c=colors, cmap=\"bwr\")\n",
    "\n",
    "    w1, w2 = w\n",
    "    x = -b / w1\n",
    "    y = -b / w2\n",
    "\n",
    "    d = y\n",
    "    c = -y / x\n",
    "\n",
    "    line_x_coords = np.array([-1, x+1])\n",
    "    line_y_coords = c * line_x_coords + d\n",
    "\n",
    "    plt.plot(line_x_coords, line_y_coords)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH+s5USn3hp/oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb592a1e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejoras\n",
    "Algunos puntos importantes que revisamos durante este proceso:\n",
    "\n",
    "## Random weights\n",
    "\n",
    "Los pesos anteriormente partieron en cero. <br>\n",
    "Esto implica que siempre que se entrene este sistema con los mismos valores de entrada, se llegará al mismo resultado. <br>\n",
    "Esto puede ser negativo en algunos casos y se recomienda iniciar los pesos con valores random:\n",
    "\n",
    "`w = random.rand(2)`\n",
    "\n",
    "`b = random.random()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:\t\t [ 0.61656278  0.32528571]\n",
      "bias:\t\t\t 0.6223595128694391\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(2)\n",
    "b = random.random()\n",
    "print(\"weights:\\t\\t\", w)\n",
    "print(\"bias:\\t\\t\\t\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implemented**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:\t\t [ 0.15635308  0.21891553]\n",
      "bias:\t\t\t 0.10548450420896882\n",
      "inputs (xi):\t\t [1, 1]\n",
      "expected (di):\t\t 1\n",
      "output (yi):\t\t 0.480753115649\n",
      "error (di-step(yi)):\t 0\n",
      "new weigth:\t\t [ 0.15635308  0.21891553]\n",
      "new bias:\t\t 0.105484504209\n"
     ]
    }
   ],
   "source": [
    "trainingData = [\n",
    "    ([0,0],0),\n",
    "    ([0,1],1),\n",
    "    ([1,0],1),\n",
    "    ([1,1],1),\n",
    "]\n",
    "\n",
    "learningRate = 0.2\n",
    "\n",
    "w = np.random.rand(2)\n",
    "print(\"weights:\\t\\t\", w)\n",
    "b = random.random()\n",
    "print(\"bias:\\t\\t\\t\", b)\n",
    "\n",
    "x, di = trainingData[i]\n",
    "print(\"inputs (xi):\\t\\t\", x)\n",
    "print(\"expected (di):\\t\\t\", di)\n",
    "\n",
    "yi = x[0] * w[0] + x[1] * w[1] + b\n",
    "print(\"output (yi):\\t\\t\", yi)\n",
    "\n",
    "error = di - step(yi)\n",
    "print(\"error (di-step(yi)):\\t\", error)\n",
    "\n",
    "w = w + learningRate * error * np.array(x)\n",
    "print(\"new weigth:\\t\\t\", w)\n",
    "\n",
    "b = b + learningRate * error\n",
    "print(\"new bias:\\t\\t\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producto Punto\n",
    "\n",
    "En vez de realizar la multiplicación de las variables de entrada por los pesos de forma manual:\n",
    "\n",
    "`yi = xi[0] * w[0] + xi[1] * w[1] + b`\n",
    "    \n",
    "Se hará el producto punto:\n",
    "\n",
    "`yi = np.dot(w, x) + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math yi:\t\t 0.469514682536\n",
      "dot yi:\t\t\t 0.469514682536\n"
     ]
    }
   ],
   "source": [
    "# Valores ejemplo\n",
    "x = [0, 1]\n",
    "w = np.random.rand(2)\n",
    "\n",
    "# Calculo de forma explícita:\n",
    "yi = x[0] * w[0] + x[1] * w[1] + b\n",
    "print(\"math yi:\\t\\t\", yi)\n",
    "\n",
    "# Calculo con producto punto:\n",
    "yi = np.dot(w, x) + b\n",
    "print(\"dot yi:\\t\\t\\t\", yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implemented**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:\t\t [ 0.00696555  0.19022055]\n",
      "bias:\t\t\t 0.07734880261049037\n",
      "inputs (xi):\t\t [1, 1]\n",
      "expected (di):\t\t 1\n",
      "output (yi):\t\t 0.274534907547\n",
      "error (di-step(yi)):\t 0\n",
      "new weigth:\t\t [ 0.00696555  0.19022055]\n",
      "new bias:\t\t 0.07734880261049037\n"
     ]
    }
   ],
   "source": [
    "trainingData = [\n",
    "    ([0,0],0),\n",
    "    ([0,1],1),\n",
    "    ([1,0],1),\n",
    "    ([1,1],1),\n",
    "]\n",
    "\n",
    "learningRate = 0.2\n",
    "\n",
    "w = np.random.rand(2)\n",
    "print(\"weights:\\t\\t\", w)\n",
    "b = random.random()\n",
    "print(\"bias:\\t\\t\\t\", b)\n",
    "\n",
    "x, di = trainingData[i]\n",
    "print(\"inputs (xi):\\t\\t\", x)\n",
    "print(\"expected (di):\\t\\t\", di)\n",
    "\n",
    "yi = np.dot(w, x) + b\n",
    "print(\"output (yi):\\t\\t\", yi)\n",
    "\n",
    "error = di - step(yi)\n",
    "print(\"error (di-step(yi)):\\t\", error)\n",
    "\n",
    "w = w + learningRate * error * np.array(x)\n",
    "print(\"new weigth:\\t\\t\", w)\n",
    "\n",
    "b = b + learningRate * error\n",
    "print(\"new bias:\\t\\t\", b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
